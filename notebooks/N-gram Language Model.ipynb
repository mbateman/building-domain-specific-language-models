{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83d5f48",
   "metadata": {},
   "source": [
    "## N-gram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f58e6",
   "metadata": {},
   "source": [
    "Split the dataset into a training and a testing subset. Use the category “title” for the testing set and the categories “comment” and “post” for the training set. The short length of titles will make them good candidates later as seeds for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d410d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f61107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/stackexchange_812k.tokenized.csv\").sample(frac=1, random_state=8).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171a181b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309845.0</td>\n",
       "      <td>I can't disclose the algorithm, but I can cert...</td>\n",
       "      <td>comment</td>\n",
       "      <td>i can ' t disclose the algorithm , but i can c...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298634.0</td>\n",
       "      <td>I plan to leave the answer to this question in...</td>\n",
       "      <td>comment</td>\n",
       "      <td>i plan to leave the answer to this question in...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>790161.0</td>\n",
       "      <td>Wait, I need to clarify how is Half-normal dis...</td>\n",
       "      <td>comment</td>\n",
       "      <td>wait , i need to clarify how is half - normal ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>268623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am fitting several models of the form.. glm ...</td>\n",
       "      <td>post</td>\n",
       "      <td>i am fitting several models of the form .. glm...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>808873.0</td>\n",
       "      <td>If you really want to calculate some p-value u...</td>\n",
       "      <td>comment</td>\n",
       "      <td>if you really want to calculate some p - value...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0   161009        NaN    309845.0   \n",
       "1   156252        NaN    298634.0   \n",
       "2   423360        NaN    790161.0   \n",
       "3   268623        NaN         NaN   \n",
       "4   433662        NaN    808873.0   \n",
       "\n",
       "                                                text category  \\\n",
       "0  I can't disclose the algorithm, but I can cert...  comment   \n",
       "1  I plan to leave the answer to this question in...  comment   \n",
       "2  Wait, I need to clarify how is Half-normal dis...  comment   \n",
       "3  I am fitting several models of the form.. glm ...     post   \n",
       "4  If you really want to calculate some p-value u...  comment   \n",
       "\n",
       "                                              tokens  n_tokens  \n",
       "0  i can ' t disclose the algorithm , but i can c...        40  \n",
       "1  i plan to leave the answer to this question in...        84  \n",
       "2  wait , i need to clarify how is half - normal ...        25  \n",
       "3  i am fitting several models of the form .. glm...        82  \n",
       "4  if you really want to calculate some p - value...        66  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d71f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the dataset\n",
    "df['tokens'] = df.tokens.apply(lambda txt : txt.split())\n",
    "\n",
    "# We split the dataset into a training and a testing subset.\n",
    "# The testing subset is composed of the titles, the train subset is composed of posts and comments\n",
    "\n",
    "df_train = df[df.category.isin(['post','comment'])].copy()\n",
    "df_test = df[df.category.isin(['title'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be937be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['the', 'lasso', 'method', 'for', 'variable', 'selection']),\n",
       "       list(['if', 'your', 'real', 'task', 'is', 'about', 'discovering', 'the', 'covariance', 'matrix', ',', 'by', 'using', 'trials', ',', 'then', 'you', 'may', 'be', 'interested', 'in', 'a', 'direct', 'analytical', 'solution', 'the', 'variance', '-', 'covariance', 'matrix', 'for', 'a', 'uniform', 'variable', ',', 'in', 'euclidean', 'space', ',', 'on', 'the', 'cube']),\n",
       "       list(['no', ',', 'i', 'don', \"'\", 't', 'think', 'as', 'i', 'go', ',', 'i', 'thin', 'afterward', '.', 'it', 'is', 'just', 'that', 'i', 'have', 'to', 'let', 'it', 'run', 'for', 'a', 'long', 'time', 'in', 'order', 'to', 'get', 'the', 'lags', 'i', 'want', '.']),\n",
       "       list(['it', 'is', 'preferable', 'to', 'do', 'this', 'exercise', 'from', 'definition', 'as', 'done', 'here']),\n",
       "       list(['well', ',', 'i', 'used', 'to', 'have', 'the', 'same', 'knowledge', 'gap', 'i', \"'\", 'm', 'referring', 'to', 'in', 'my', 'question', '.', 'it', 'seems', 'to', 'be', 'more', 'a', 'reflection', 'of', 'people', \"'\", 's', 'interests', ',', 'knowledge', 'and', 'how', 'they', 'get', 'introduced', 'to', 'the', 'software', 'rather', 'than', 'the', 'software', 'itself', '.', 'but', 'default', 'options', 'play', 'a', 'large', 'part', 'as', 'well', 'with', 'the', 'default', 'type', 'iii', 'option', 'being', 'used', 'in', 'spss', '.'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5).tokens.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8272934",
   "metadata": {},
   "source": [
    "## Build the matrix of prefix—word frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d74b7",
   "metadata": {},
   "source": [
    "### Use the ngrams function from nltk.utils to generate all n-grams from the corpus and set the following left_pad_symbol =  \\<s> and right_pad_symbol = \\</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b733abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309845.0</td>\n",
       "      <td>I can't disclose the algorithm, but I can cert...</td>\n",
       "      <td>comment</td>\n",
       "      <td>[i, can, ', t, disclose, the, algorithm, ,, bu...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298634.0</td>\n",
       "      <td>I plan to leave the answer to this question in...</td>\n",
       "      <td>comment</td>\n",
       "      <td>[i, plan, to, leave, the, answer, to, this, qu...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>790161.0</td>\n",
       "      <td>Wait, I need to clarify how is Half-normal dis...</td>\n",
       "      <td>comment</td>\n",
       "      <td>[wait, ,, i, need, to, clarify, how, is, half,...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>268623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am fitting several models of the form.. glm ...</td>\n",
       "      <td>post</td>\n",
       "      <td>[i, am, fitting, several, models, of, the, for...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>808873.0</td>\n",
       "      <td>If you really want to calculate some p-value u...</td>\n",
       "      <td>comment</td>\n",
       "      <td>[if, you, really, want, to, calculate, some, p...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0   161009        NaN    309845.0   \n",
       "1   156252        NaN    298634.0   \n",
       "2   423360        NaN    790161.0   \n",
       "3   268623        NaN         NaN   \n",
       "4   433662        NaN    808873.0   \n",
       "\n",
       "                                                text category  \\\n",
       "0  I can't disclose the algorithm, but I can cert...  comment   \n",
       "1  I plan to leave the answer to this question in...  comment   \n",
       "2  Wait, I need to clarify how is Half-normal dis...  comment   \n",
       "3  I am fitting several models of the form.. glm ...     post   \n",
       "4  If you really want to calculate some p-value u...  comment   \n",
       "\n",
       "                                              tokens  n_tokens  \n",
       "0  [i, can, ', t, disclose, the, algorithm, ,, bu...        40  \n",
       "1  [i, plan, to, leave, the, answer, to, this, qu...        84  \n",
       "2  [wait, ,, i, need, to, clarify, how, is, half,...        25  \n",
       "3  [i, am, fitting, several, models, of, the, for...        82  \n",
       "4  [if, you, really, want, to, calculate, some, p...        66  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca76643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, '</s>')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "list(\n",
    "    ngrams([1,2,3,4,5]\n",
    "            , 2\n",
    "            , pad_left=True\n",
    "            , pad_right=True\n",
    "            , left_pad_symbol='<s>'\n",
    "            , right_pad_symbol='</s>'\n",
    "          )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c0cea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 705964/705964 [01:04<00:00, 10901.18it/s]\n"
     ]
    }
   ],
   "source": [
    "ngrams_degree = 3\n",
    "counts = defaultdict(Counter)\n",
    "for tokens in tqdm(df_train.tokens.values):\n",
    "    for ngram in ngrams(\n",
    "            tokens, \n",
    "            n= ngrams_degree,  \n",
    "            pad_right=True, \n",
    "            pad_left=True, \n",
    "            left_pad_symbol=\"<s>\", \n",
    "            right_pad_symbol=\"</s>\"):\n",
    "        prefix = ngram[:ngrams_degree-1]\n",
    "        token = ngram[ngrams_degree-1]\n",
    "        counts[prefix][token] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4cbec5",
   "metadata": {},
   "source": [
    "## Write a text generation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad44fc",
   "metadata": {},
   "source": [
    "- Takes a bigram as input and generates the next token\n",
    "- iteratively slide the prefix over the generated text so that the new prefix includes the most recent token; generates the next token\n",
    "- to generate each next token, sample the list of words associated with the prefix using the probability distribution of the prefix\n",
    "- stop the text generation when a certain number of words have been generated or the latest token is a </s>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d6ebdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dictionary):\n",
    "    summed = math.fsum(dictionary.values())\n",
    "    return { k : round(v/summed, 4) for k, v in dictionary.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bdc49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = defaultdict(dict)\n",
    "for prefix, tokens in counts.items():\n",
    "    freq[prefix] = normalize({token : counts[prefix][token] for token in tokens })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "849a0739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('generally', 'bother'): \t{'with': 1.0}\n",
      "('originally', '</s>'): \t{'</s>': 1.0}\n",
      "('american', 'psychologist'): \t{',': 0.8864, 'there': 0.0227, 'entitled': 0.0227, 'useful': 0.0227, 'that': 0.0227, 'article': 0.0227}\n",
      "('curve', 'in'): \t{'your': 0.0168, 'the': 0.3575, 'references': 0.0056, 'between': 0.0056, 'time': 0.0056, '-': 0.0056, 'order': 0.0726, 'statistics': 0.0112, 'a': 0.0726, 'some': 0.0279, 'research': 0.0056, 'using': 0.0056, 'test': 0.0056, 'my': 0.0223, 'this': 0.0615, 'r': 0.0279, 'most': 0.0056, 'matlab': 0.0056, 'black': 0.0056, 'to': 0.0056, 'hypothesis': 0.0112, 'blue': 0.0112, 'sklearn': 0.0056, 'large': 0.0056, 'spss': 0.0112, ',': 0.0056, 'areas': 0.0056, 'excel': 0.0056, 'each': 0.0112, 'group': 0.0056, 'toward': 0.0056, 'that': 0.0056, 'd': 0.0056, 'general': 0.0112, 'kg': 0.0056, 'figure': 0.0112, 'page': 0.0056, 'item': 0.0056, 'red': 0.0112, 'ggplot': 0.0056, 'cross': 0.0056, 'python': 0.0056, 'microsoft': 0.0056, 'starting': 0.0056, 'terms': 0.0168, 'his': 0.0056, 'such': 0.0112, 'tablecurve': 0.0056, 'different': 0.0056, 'both': 0.0056, 'or': 0.0056, 'it': 0.0112, 'function': 0.0056, 'green': 0.0056, 'ordinary': 0.0056, 'azure': 0.0056, 'weka': 0.0056}\n",
      "('matrix', 'pose'): \t{'a': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prefix = random.choice(list(freq.keys()))\n",
    "    print(\"{}: \\t{}\".format(prefix,freq[prefix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b868a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = defaultdict(dict)\n",
    "def generate(text, n_words = 40):\n",
    "    for i in range(n_words):\n",
    "        prefix = tuple(text.split()[-ngrams_degree+1:])\n",
    "        # no available text\n",
    "        if len(freq[prefix]) == 0:\n",
    "            break\n",
    "        candidates = list(freq[prefix].keys())\n",
    "        probas     = list(freq[prefix].values())\n",
    "        probas = np.array(probas)\n",
    "        probas /= probas.sum()\n",
    "        text      += ' ' + np.random.choice(candidates, p = probas)\n",
    "        if text.endswith('</s>'):\n",
    "            break\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f3e1ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the model , but these will be more appropriate when there is greater than the model , you can see , thanks that ' s possible to calculate the relative strength of binding affinities min and max lifetime more than once you\n",
      "\n",
      "that distribution . statistical science by solving the problem you ' re mostly measuring much the same mathematical thing are more sophisticated ideas like hyperloglog and its expensive for a normal approximation with fewer runs . the closer you can separate them\n",
      "\n",
      "to determine the relative risk which is why we use this method and how much automation is built by having a hard time believing this ? thanks . how do i need some explaining to their p - value without violating super\n"
     ]
    }
   ],
   "source": [
    "text      = 'the model'\n",
    "print()\n",
    "print(generate(text))\n",
    "\n",
    "print()\n",
    "text      = 'that distribution'\n",
    "print(generate(text))\n",
    "\n",
    "print()\n",
    "text      = 'to determine'\n",
    "print(generate(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc779d7e",
   "metadata": {},
   "source": [
    "## Write a function that can estimate the probability of a sentence and use it to select the most probable sentence out of several candidate sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b31ff1",
   "metadata": {},
   "source": [
    "- Split the sentence into trigrams and use the chain rule to calculate the probability of the sentence as a product of the bigrams—tokens probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ff0f1",
   "metadata": {},
   "source": [
    "Estimate the probability of a sentence and use it to select the most probable sentence out of several candidate sentences using the code snippet shared below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "909bf243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temp(text, temperature = 1, n_words=30):\n",
    "    for i in range(n_words):\n",
    "        prefix = tuple(text.split()[-ngrams_degree+1:])\n",
    "        # no available next word\n",
    "        if len(freq[prefix]) == 0:\n",
    "            break\n",
    "        candidates  = list(freq[prefix].keys())\n",
    "        initial_probas = list(freq[prefix].values())\n",
    "        # modify distribution\n",
    "        denom   = sum( [ p ** temperature for p in initial_probas ] )\n",
    "        probas  = [ p ** temperature / denom  for p in initial_probas ]\n",
    "        text       += ' ' + np.random.choice(candidates, p = probas)\n",
    "        if text.endswith('</s>'):\n",
    "            break\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "282e9bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the model is capturing seasonality properly . you would make sense to interpolate between points . </s>\n",
      "\n",
      "that distribution ? is your description , but it is simple to express the value of outcome you regard patients as sick retrieved . on noisy observations is smaller than the median\n",
      "\n",
      "to determine sensitivity and specificity happen to the population sizes of fish per unit time days until the predictions and confidence interval has only participants for correction for overdispersion which means i\n"
     ]
    }
   ],
   "source": [
    "text      = 'the model'\n",
    "print()\n",
    "print(generate_temp(text))\n",
    "\n",
    "print()\n",
    "text      = 'that distribution'\n",
    "print(generate_temp(text))\n",
    "\n",
    "print()\n",
    "text      = 'to determine'\n",
    "print(generate_temp(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515cf49",
   "metadata": {},
   "source": [
    "## Implement the perplexity scoring function for a given sentence and for the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a9bef",
   "metadata": {},
   "source": [
    "Use the following code snippet to deal with the missing ngrams and tokens using Laplace smoothing. Skip missing elements to make function run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9aaecca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the perplexity on some sentences.\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def perplexity(sentence):\n",
    "    sentence = tokenizer.tokenize(sentence.lower())\n",
    "    N = len(sentence)\n",
    "    logprob = 0\n",
    "\n",
    "    for ngram in ngrams(\n",
    "          sentence, \n",
    "          n= ngrams_degree,  \n",
    "          pad_right=True, pad_left=True, \n",
    "          left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"):\n",
    "        try:\n",
    "            prefix = ngram[:ngrams_degree-1] \n",
    "            token = ngram[ngrams_degree-1]\n",
    "            logprob += np.log( freq[ prefix ][token]  )\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return np.exp(- logprob / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b421d464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1051.7392900892169\n",
      "\n",
      "12757.759076995711\n",
      "\n",
      "8858.233390878902\n"
     ]
    }
   ],
   "source": [
    "text      = 'the model'\n",
    "print()\n",
    "print(perplexity(text))\n",
    "\n",
    "print()\n",
    "text      = 'that distribution'\n",
    "print(perplexity(text))\n",
    "\n",
    "print()\n",
    "text      = 'to determine'\n",
    "print(perplexity(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe71cb2",
   "metadata": {},
   "source": [
    "## Implement Additive Laplace smoothing to give a non-zero probability to missing prefix—token combinations when calculating perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93f2e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def perplexity_laplace(sentence,delta = 1):\n",
    "    sentence = tokenizer.tokenize(sentence.lower())\n",
    "    N = len(sentence)\n",
    "    logprob = 0\n",
    "    for ngram in ngrams(\n",
    "          sentence, \n",
    "          n= ngrams_degree,  \n",
    "          pad_right=True, pad_left=True, \n",
    "          left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"):\n",
    "        prefix = ngram[:ngrams_degree-1]\n",
    "        token = ngram[ngrams_degree-1]\n",
    "        if prefix in list(counts.keys()):\n",
    "            total = sum( counts[prefix].values()  )\n",
    "            if token in counts[prefix].keys():\n",
    "                # normal calculation\n",
    "                logprob += np.log( (counts[prefix][token] + delta)/ (total + delta * N ) )\n",
    "            else:\n",
    "                logprob += np.log( ( delta)/ (total + delta * N ) )\n",
    "        else:\n",
    "            logprob += - np.log( N )\n",
    "\n",
    "    return np.exp(-logprob / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e08793bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[perplexity 142.66] this model belongs on a different planet\n",
      "[perplexity 35.50] this question really belongs on a different site.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"this model belongs on a different planet\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity_laplace(sentence, delta = 10), sentence))\n",
    "\n",
    "sentence = \"this question really belongs on a different site.\"\n",
    "print(\"[perplexity {:.2f}] {}\".format(perplexity_laplace(sentence, delta = 10), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1e04809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[perplexity 319.66] this model belongs on a different planet\n",
      "\n",
      "[perplexity 36.10] this question really belongs on a different site.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"this model belongs on a different planet\"\n",
    "print(\"\\n[perplexity {:.2f}] {}\".format(perplexity_laplace(sentence, delta = 1), sentence))\n",
    "\n",
    "sentence = \"this question really belongs on a different site.\"\n",
    "print(\"\\n[perplexity {:.2f}] {}\".format(perplexity_laplace(sentence, delta = 1), sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32083efe",
   "metadata": {},
   "source": [
    "## Calculate the perplexity of the language model on the test set composed of titles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5616d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21542.76845163307"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [logproba_sentence(sentence) for sentence in corpus]\n",
    "score = np.ma.masked_invalid(scores).sum()\n",
    "- score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4dd1b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_perplexity(corpus):\n",
    "    # start by calculating the total number of tokens in the corpus\n",
    "    token_count = np.sum([len(tokenizer.tokenize(sentence)) for sentence in corpus])\n",
    "    logproba_corpus_scores = np.array([logproba_sentence(sentence) for sentence in corpus])\n",
    "    logproba_corpus = np.ma.masked_invalid(logproba_corpus_scores).sum()\n",
    "    perplexity =  np.multiply((1/token_count), logproba_corpus)\n",
    "    print(token_count, logproba_corpus)\n",
    "    return -perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "baf8f45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10334 -21542.76845163307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.084649550187059"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def logproba_sentence(sentence, delta = 1):\n",
    "    sentence = tokenizer.tokenize(sentence.lower())\n",
    "    logprob = 0\n",
    "    for ngram in ngrams(\n",
    "        sentence, n= ngrams_degree,  \n",
    "        pad_right=True, pad_left=True, \n",
    "        left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"):\n",
    "        prefix = ngram[:ngrams_degree-1]\n",
    "        token = ngram[ngrams_degree-1]\n",
    "        try:\n",
    "            logprob += np.log( freq[prefix][token] )\n",
    "        except:\n",
    "              pass\n",
    "    return logprob\n",
    "\n",
    "# The perplexity of a sample of 1000 titles\n",
    "corpus = df_test.text.sample(1000, random_state = 8).values\n",
    "corpus_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec786235",
   "metadata": {},
   "source": [
    "## Try to improve the perplexity score of your model by:\n",
    "- modifying the preprocessing phase of the corpus,\n",
    "- increasing or decreasing number of tokens in the model (bi grams, 4-grams, etc.),\n",
    "- varying the delta parameter in the Additive Laplace smoothing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f9b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
